q()
 quality = read.csv("quality.
 quality = read.csv("quality.csv")
 quality = read.csv("quality.csv")
getwd()
 quality = read.csv("quality.csv")
install.packages("caTools")
library(caTools)
set.seed(88)
split = sample.split(quality$PoorCare , splitRatio = 0.75)
split = sample.split(quality$PoorCare , SplitRatio = 0.75)
Split
split
qualityTrain = subset(quality, split == TRUE)
qualiyTest = subset(quality, split == False)
qualiyTest = subset(quality, split == FALSE)
nrow(qualityTrain)
nrow(qualityTest)
nrow(qualiyTest)
qualityLog = glm(PoorCare ~ StartedOnCombination + ProviderCount, data=qualityTrain, family=binomial)
summary(qualityLog)
predictTrain = predict(qualityLog, type="response")
summary(predictTrain)
tapply(predictrain, qualityTrain$PoorCare, mean)
tapply(predictTrain, qualityTrain$PoorCare,mean)
save.image("C:\\Users\\deepak\\Downloads\\logistic regression")
save.image("C:\\Users\\deepak\\Downloads\\logistic regression.R")
20/25
15/25
predictTest = predict(QualityLog, type="response", newdata=qualityTest)
You can compute the test set AUC by running the following two commands in R:
ROCRpredTest = prediction(predictTest, qualityTest$PoorCare)
auc = as.numeric(performance(ROCRpredTest, "auc")@y.values)
clearscreen
stevens = read.csv("stevens.csv")
str(stevens)
#spliting data for training and test
library(caTools)
set.seed(3000)
spl = sample.split(stevens$Reverse, SplitRatio=0.7))
spl = sample.split(stevens$Reverse, SplitRatio=0.7)
Train = subset(sevens,spl==TRUE)
Train = subset(stevens,spl==TRUE)
Test = subset(stevens,spl==FALSE)
install.packages("rpart")
library(rpart)
install.packages("rpart.plot")
library(rpart.plot)
stevensTree = rpart(Reverse ~ Circuit + Issue + Petitioner + Respondent +LowerCourt + Unconst,data=Train, method="Class", minbucket=25)
stevensTree = rpart(Reverse ~ Circuit + Issue + Petitioner + Respondent +LowerCourt + Unconst,data=Train, method="class", minbucket=25)
prp(stevensTree)
prp(stevensTree)
PredictCART = predict(stevensTree, newdata= Test, type="class")
table(Test$Reverse,PredictCART)
(41+71)/(41+36+71)
(41+71)/(41+36+22+71)
#probability of accuracy
library(ROCR)
install.packages("ROCR")
library(ROCR)
PredictROC = predict(stevensTree, newdata=Test)
PredictROC
# each number is probability of 0 and 1
pred = prediction(PredictROC[,2], Test$Reverse)
Perf = performance(pred,"tpr","fpr")
plot(perf)
plot(Perf)
save.image("C:\\Users\\deepak\\Downloads\\CART")
as.numeric(performance(pred, "auc")@y.values)
stevensTree = rpart(Reverse ~ Circuit + Issue + Petitioner + Respondent +LowerCourt + Unconst,data=Train, method="class", minbucket=5)
prp(stevensTree)
stevensTree = rpart(Reverse ~ Circuit + Issue + Petitioner + Respondent +LowerCourt + Unconst,data=Train, method="class", minbucket=100)
prp(stevensTree)
save.image("C:\\Users\\deepak\\Downloads\\AUC and minbucket size")
install.packages("randomForest")
library(randomForest)
stevensForest = randomForest(Reverse ~ Circuit + Issue + Petitioner + Respondent + LowerCourt +Unconst, data=rain, nodesize=200)
stevensForest = randomForest(Reverse ~ Circuit + Issue + Petitioner + Respondent + LowerCourt +Unconst, data=Train, nodesize=200)
Train$Reverse = as.factor(Train$Reverse)
Test$Reverse = as.factor(Test$Reverse)
stevensForest = randomForest(Reverse ~ Circuit + Issue + Petitioner + Respondent + LowerCourt +Unconst, data=Train, nodesize=200)
PredictForest = predict(stevensForest, newdata=Test)
table(PredictForest)
table(Test$Reverse,PredictForest)
(51+67)/(51+26+26+67)
#accurac increase over CART # this number is random for each other as trees create are random
save.image("C:\\Users\\deepak\\Downloads\\Random forest.R")
stevensForest = randomForest(Reverse ~ Circuit + Issue + Petitioner + Respondent + LowerCourt +Unconst, data=Train, nodesize=100)
PredictForest = predict(stevensForest, newdata=Test)
table(PredictForest)
table(Test$Reverse,PredictForest)
(40+75)/(40+37+18+75)
stevensForest = randomForest(Reverse ~ Circuit + Issue + Petitioner + Respondent + LowerCourt +Unconst, data=Train, nodesize=200)
PredictForest = predict(stevensForest, newdata=Test)
table(Test$Reverse,PredictForest)
(49+69)/(49+28+24+69)
PredictForest = predict(stevensForest, newdata=Test)
install.packeges("caret")
install.packages("caret")
library(caret)
install.packages("caret")
library(caret)
library(caret)
install.packages("e1071")
library(e1071)
numFolds = trainControl(method="cv"number=10)
numFolds = trainControl(method="cv",number=10)
cpGrid = expand.grid(.cp=seq(0.01,0.5,0.001)))
cpGrid = expand.grid(.cp=seq(0.01,0.5,0.001))
train(Reverse ~ Circuit,Issue,Petitioner,Respondent,LowerCourt,Unconst,data=Train,method="rpart",trcontrol=numfolds,tuneGrid=cpGrid)
stevensTreeCV = rpart(Reverse,Circuit,Issue,Petitioner,Respondent,LowerCourt,Unconst,data=Train,method="class",cp=0.18)
stevensTreeCV = rpart(Reverse,Circuit,Issue,Petitioner,LowerCourt,Unconst,data=Train,method="class",cp=0.18)
PredictCV = predict(stevensTreeCV,newdata=Test,type="class")
table(Test$stevens,PredictCV)
install.packeges("caret")
install.packages("caret")
library(caret)
install.packages("ggplot2")
library(ggplot2)
library(caret)
library(ggplot2)
install.packages("tibble")
install.packages("e1071")
library(e1071)
#dependency listed
#defining how many folds we want
nFolds = trainControl(method="cv",number=10)
utils:::menuInstallPkgs()
utils:::menuInstallPkgs()
nFolds = trainControl(method="cv",number=10)
tweets = read.csv("tweets.csv",stringAsFactors=FALSE)
tweets = read.csv("tweets.csv",stringsAsFactors=FALSE)
str(tweets)
tweetsNegative = as.factor(tweets$Avg <= -1)
table(tweetsNegative)
#about 50% negative
install.packages("tm")
library(tm)
install.packages("SnowballC")
library(SnowballC)
utils:::menuInstallPkgs()
library(SnowballC)
corpus = Corpus(VectorSource(tweets$Tweet))
corpus
corpus[[1]]
corpus = tm_map(corpus, tolower)
corpus[[1]]
corpus = tm_map(corpus, removePunctuation)
corpus[[1]]
#removing stopwords
stopwords("english")[1:10]
corpus = tm_map(corpus, removeWords)
corpus = tm_map(corpus, removeWords,c("apple",stopwords("english")))
corpus[[1]]
corpus = tm_map(corpus,stemDocument)
corpus[[1]]
save.image("C:\\Users\\deepak\\Downloads\\Natural language Processing.R")
frequencies = DocumentTermMatrix(corpus)
frequencies
findFreqTerms(frequencies,lowfreq=20)
findFreqTerms(frequencies,lowfreq=100)
sparse = removeSparseTerms(frquencies,0.995)
sparse = removeSparseTerms(frequencies,0.995)
tweetSparse = as.data.frame(as.matrix(sparse))
colnames(tweetSparse) = make.name(colnames(tweetSparse))
colnames(tweetSparse) = make.names(colnames(tweetSparse))
tweetsSparse$Negative = tweets$Negative
tweetSparse$Negative = tweets$Negative
library(caTools)
set.seed(123)
split = sample.split(tweetSparse$Negative,SplitRatio=0.7)
split = sample.split(tweetSparse$Negative,SplitRatio=[0,0.7])
split = sample.split(tweetSparse$Negative,splitRatio=0.7)
split = sample.split(tweetSparse$Negative,SplitRatio=0.7)
trainSparse = subset(tweetSparse,split == TRUE)
testSparse = subset(tweetSparse,split == FALSE)
predictions = predict(tweetLog, newdata=testSparse, type="response")
library(rpart)
library(rpart.plot)
predictions = predict(tweetLog, newdata=testSparse, type="response")
tweetLog = rpart(Negative ~ ., data=trainSparse,method="class")
tweetLog = glm(Negative ~ .,data=trainSparse, family=binomial)
tweetLog = glm(rainSparse$Negative ~ .,data=trainSparse, family=binomial)
tweetLog = glm(trainSparse$Negative ~ .,data=trainSparse, family=binomial)
q()
